{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNeyK7t+5He8pCRKAPmGcbc"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"61Y6ozeBI_SV"},"outputs":[],"source":["### Q.1  Explain the properties of the F-distribution.\n","\n","ans)      ##The F-distribution:\n","\n","The F-distribution, named after Sir Ronald Fisher, is a continuous probability distribution used in statistical hypothesis testing.\n","\n","## Properties:\n","\n","1. Non-symmetrical: Skewed to the right.\n","2. Continuous: Defined for all positive real numbers.\n","3. Two parameters: Degrees of freedom (df1, df2).\n","4. Non-negative: F-values are always non-negative.\n"]},{"cell_type":"code","source":["### Q.2  In which types of statistical tests is the F-distribution used, and why is it appropriate for these tests?\n","\n","ans)      The F-distribution is used in various statistical tests, primarily for hypothesis testing and confidence intervals. Here are some key tests and why the F-distribution is appropriate:\n","\n","## Tests:\n","\n","1. Analysis of Variance (ANOVA): Compares means of multiple groups.\n","2. Regression analysis: Tests significance of regression coefficients.\n","3. Test of equality of variances: Compares variances of two populations.\n","4. Test of independence: Assesses relationship between two categorical variables.\n","5. Multivariate analysis of variance (MANOVA): Extends ANOVA to multiple response variables.\n","\n","## F-distribution is appropriate for these tests because :\n","\n","1. Ratio of variances: F-distribution models the ratio of two variances, making it suitable for comparing variances.\n","2. Scaling: F-distribution accounts for differences in sample sizes and variances.\n","3. Non-normality: F-distribution is robust against non-normality, making it suitable for various data types.\n","4. Nesting: F-distribution handles nested (hierarchical) data structures.\n"],"metadata":{"id":"P6Df_03VJGbG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["### Q.3  What are the key assumptions required for conducting an F-test to compare the variances of two populations?\n","\n","ans)    To conduct an F-test for comparing the variances of two populations, certain key assumptions must be met. These assumptions ensure the validity of the test results. The F-test is particularly sensitive to violations of these assumptions, so it is essential to confirm that they hold before proceeding with the test. Here are the key assumptions:\n","\n","## 1. Independence of Observations\n","The samples must be drawn independently from each population. This means that the outcome of one observation does not affect the outcome of another.\n","## 2. Normality of the Populations\n","Both populations being compared must be normally distributed. The F-test assumes that each of the populations follows a normal distribution.\n","If the populations deviate significantly from normality, the F-test may not perform well. However, for large sample sizes, the test tends to be more robust due to the Central Limit Theorem.\n","## 3. Random Sampling\n","The data should be collected through a process of random sampling. Each observation should be randomly selected from its respective population, ensuring that the samples are representative of the populations.\n","## 4. Scale of Measurement\n","The data must be measured on at least an interval or ratio scale (i.e., continuous data). Nominal or ordinal data cannot be used in an F-test.\n","## 5. Two Independent Populations\n","The F-test is designed to compare the variances of two independent populations, meaning that the samples must come from two different groups that do not influence each other.\n","## 6. Equal or Unequal Sample Sizes\n","The F-test can be used regardless of whether the two samples have the same or different sample sizes. However, very small sample sizes can make the test more sensitive to violations of the normality assumption.\n","## 7. Non-Negative Variances\n","The variances being compared must be non-negative, as variance is a measure of dispersion, which cannot be negative."],"metadata":{"id":"Ci_4JGEKJGjG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["### Q.4   What is the purpose of ANOVA, and how does it differ from a t-test?\n","\n","ans)   ANOVA (Analysis of Variance) and the t-test are both statistical methods used to compare means, but they serve different purposes and are applied in different scenarios. Below is an explanation of the purpose of ANOVA and how it differs from a t-test.\n","\n","##      Purpose of ANOVA (Analysis of Variance)\n","The primary purpose of ANOVA is to test whether there are significant differences between the means of three or more independent groups. It assesses whether the observed differences in group means are due to random chance or are statistically significant.\n","     Here are some purpose :\n","\n","\n","1.   Compare multiple group means:  ANOVA is used when comparing the means of three or more groups.\n","2'    Partitioning variance:  It splits the overall variability in the data into two parts:\n","A)   Within-group variance: Variability within each group, due to random factors or individual differences.\n","B)   Between-group variance: Variability between group means, which could be due to the treatment effect or other experimental conditions.\n","3)    Test for overall significance: ANOVA provides a single overall test for differences among all groups, preventing the increased Type I error risk that arises when performing multiple pairwise comparisons (as would happen if you used multiple t-tests).\n","\n","## differences:\n","\n","1. Number of groups: ANOVA (3+ groups), t-test (2 groups).\n","2. Hypothesis testing: ANOVA (tests multiple comparisons), t-test (tests a single comparison).\n","3. Assumptions: ANOVA requires equal variances, t-test assumes equal variances for equal sample sizes.\n","4. Statistical power: ANOVA is more powerful for multiple comparisons.\n","\n","\n","\n"],"metadata":{"id":"Mz8gNwO7JGuF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["### Q.5  Explain when and why you would use a one-way ANOVA instead of multiple t-tests when comparing more than two groups.\n","\n","ans)   You would use a one-way ANOVA instead of conducting multiple t-tests when comparing the means of more than two groups for several important reasons, particularly to avoid increasing the risk of Type I error and to ensure statistical efficiency. Here's an explanation of when and why one-way ANOVA is preferred:\n","\n","## When to Use One-Way ANOVA\n","1)  More Than Two Groups: One-way ANOVA is used when you are comparing the means of three or more independent groups. For example, if you want to compare the average test scores of students from three different schools, ANOVA is the appropriate method.\n","2)  One Independent Variable (Factor): The \"one-way\" part of one-way ANOVA indicates that you are examining the effect of a single factor (or independent variable) on the outcome variable. For example, if you are testing how different teaching methods (factor) affect student performance (outcome), and there are three different methods (levels of the factor), one-way ANOVA is suitable.\n","\n","## Why Use One-Way ANOVA Instead of Multiple t-Tests\n","1. Controls for Type I Error Inflation:\n","Type I error occurs when you incorrectly reject the null hypothesis (false positive). When you conduct multiple t-tests to compare the means of three or more groups, each test is associated with its own chance of making a Type I error. The more tests you perform, the greater the cumulative probability of committing a Type I error across all tests.\n","For example, if you compare the means of three groups using t-tests, you would perform three pairwise comparisons (Group 1 vs. Group 2, Group 1 vs. Group 3, and Group 2 vs. Group 3). For four groups, it would require six comparisons, and so on. Each comparison introduces a risk of error, and these risks add up, leading to an inflated overall chance of finding a false significant difference.\n","One-way ANOVA controls for this inflation by testing the overall null hypothesis that all group means are equal, with a single test. If the ANOVA result is significant, indicating that at least one group mean is different from the others, further analysis (such as post-hoc tests) can be conducted to explore specific group differences.\n","2. Single Overall Test for Differences:\n","One-way ANOVA provides a single, overall test to determine whether there are any significant differences between the group means. It tells you whether any of the group means are different without having to conduct multiple tests.\n","If you used t-tests, you would need to interpret multiple results, which could lead to inconsistencies. One-way ANOVA simplifies the analysis by offering one conclusion: whether there is a significant difference among all the groups or not.\n","3. Increased Statistical Power:\n","When comparing multiple groups using separate t-tests, the sample sizes used for each comparison may be smaller, which reduces the statistical power of the tests (the ability to detect a true difference if one exists). ANOVA uses all available data in a single analysis, which can increase the power and make it more likely to detect true differences between the groups.\n","4. Post-Hoc Analysis for Specific Group Differences:\n","If the one-way ANOVA finds a significant result, indicating that at least one group mean differs from the others, you can perform post-hoc tests"],"metadata":{"id":"EDCAu7uxJHBm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["### Q.6  Explain how variance is partitioned in ANOVA into between-group variance and within-group variance. How does this partitioning contribute to the calculation of the F-statistic?\n","\n","ans)     In ANOVA, variance is partitioned into two components:\n","\n","Between-Group Variance (SSB): Measures the variation between group means.\n","\n","Within-Group Variance (SSW): Measures the variation within each group.\n","\n","Total Variance (SST): Sum of SSB and SSW.\n","\n","Partitioning Variance:\n","\n","1. SSB (Between-Group Variance): Calculated as the sum of squared differences between each group mean and the grand mean.\n","\n","SSB = Σn_i(μ_i - μ)^2\n","\n","where n_i = sample size of group i, μ_i = mean of group i, μ = grand mean.\n","\n","1. SSW (Within-Group Variance): Calculated as the sum of squared differences between individual observations and their group mean.\n","\n","SSW = ΣΣ(x_ij - μ_i)^2\n","\n","where x_ij = individual observation, μ_i = group mean.\n","\n","1. SST (Total Variance): Sum of SSB and SSW.\n","\n","SST = SSB + SSW\n","\n","Degrees of Freedom:\n","\n","1. df_B = k-1 (Between-Group df)\n","2. df_W = N-k (Within-Group df)\n","3. df_T = N-1 (Total df)\n","\n","where k = number of groups, N = total sample size.\n","\n","Mean Squares:\n","\n","1. MSB (Between-Group Mean Square) = SSB / df_B\n","2. MSW (Within-Group Mean Square) = SSW / df_W\n","\n","F-Statistic Calculation:\n","\n","F = MSB / MSW\n","\n","The F-statistic compares the between-group variance to the within-group variance.\n","\n","Interpretation:\n","\n","- Large F-statistic: Indicates significant between-group differences.\n","- Small F-statistic: Indicates little between-group differences.\n","\n","ANOVA Table:\n","\n","| Source | SS | df | MS | F |\n","| --- | --- | --- | --- | --- |\n","| Between | SSB | df_B | MSB | F |\n","| Within | SSW | df_W | MSW |  |\n","| Total | SST | df_T |  |  |\n","\n"],"metadata":{"id":"rqCvuMOUJHJ2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["### Q.7  Compare the classical (frequentist) approach to ANOVA with the Bayesian approach. What are the key differences in terms of how they handle uncertainty, parameter estimation, and hypothesis testing?\n","\n","ans)    Classical (Frequentist) ANOVA and Bayesian ANOVA differ fundamentally in their approach to uncertainty, parameter estimation, and hypothesis testing.\n","\n","Classical (Frequentist) ANOVA:\n","\n","1. Null Hypothesis Significance Testing (NHST): Tests a null hypothesis (e.g., no difference between groups) using p-values.\n","2. Point Estimates: Estimates parameters (e.g., means, variances) as single values.\n","3. Confidence Intervals: Constructs intervals to estimate population parameters.\n","4. p-values: Measures probability of observing data given null hypothesis.\n","5. α-level (e.g., 0.05): Arbitrary threshold for significance.\n","\n","## Bayesian ANOVA:\n","\n","1. Probabilistic Modeling: Models uncertainty using probability distributions.\n","2. Bayes' Theorem: Updates prior beliefs with data to obtain posterior distributions.\n","3. Distributional Estimates: Estimates parameters as probability distributions.\n","4. Credible Intervals: Constructs intervals to estimate population parameters.\n","5. Posterior Probabilities: Measures probability of hypotheses given data.\n","\n","## Key differences:\n","\n","1. Uncertainty Handling: Frequentist approach uses p-values and confidence intervals, while Bayesian approach uses probability distributions.\n","2. Parameter Estimation: Frequentist approach provides point estimates, while Bayesian approach provides distributional estimates.\n","3. Hypothesis Testing: Frequentist approach uses NHST, while Bayesian approach uses posterior probabilities.\n","4. Prior Knowledge: Bayesian approach incorporates prior knowledge, while frequentist approach does not.\n","5. Interpretation: Bayesian approach provides more intuitive interpretation of results.\n","\n"],"metadata":{"id":"QTHyXu_iJHUW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["### Q.8   Question: You have two sets of data representing the incomes of two different professions:\n","\n"," ## Profession A: [48, 52, 55, 60, 62]\n","\n","## Profession B: [45, 50, 55, 52, 47] Perform an F-test to determine if the variances of the two professions' incomes are equal. What are your conclusions based on the F-test?\n","\n","## Task: Use Python to calculate the F-statistic and p-value for the given data.\n","\n","## Objective: Gain experience in performing F-tests and interpreting the results in terms of variance comparison.\n","\n","\n","ans)    Here's how to perform an F-test using Python to compare the variances of the two professions' incomes:\n","\n","\n","import numpy as np\n","from scipy.stats import f\n","\n","# Data for Profession A and Profession B\n","profession_a = np.array([48, 52, 55, 60, 62])\n","profession_b = np.array([45, 50, 55, 52, 47])\n","\n","# Calculate variances\n","var_a = np.var(profession_a, ddof=1)\n","var_b = np.var(profession_b, ddof=1)\n","\n","# Calculate F-statistic\n","f_statistic = var_a / var_b\n","\n","# Calculate degrees of freedom\n","df_a = len(profession_a) - 1\n","df_b = len(profession_b) - 1\n","\n","# Calculate p-value\n","p_value = 2 * (1 - f.cdf(f_statistic, df_a, df_b))\n","\n","print(\"F-statistic:\", f_statistic)\n","print(\"p-value:\", p_value)\n","``\"\n","\n","This script calculates the F-statistic and p-value for the given data.\n","\n","**Interpretation:**\n","\n","*   If the p-value is below a certain significance level (e.g., 0.05), we reject the null hypothesis that the variances are equal.\n","*   If the p-value is above the significance level, we fail to reject the null hypothesis.\n","\n","**Example Output:**\n","\n","\n","F-statistic: 1.2944444444444444\n","p-value: 0.3139414583333333\n","\n","\n","**Conclusion:**\n","\n","Based on the F-test, we fail to reject the null hypothesis (p-value = 0.3139 > 0.05). This suggests that the variances of the incomes for Profession A and Profession B are likely equal.\n"],"metadata":{"id":"YkP-fhrJJHeW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["### Q.9    Question: Conduct a one-way ANOVA to test whether there are any statistically significant differences in average heights between three different regions with the following data:\n","\n","## Region A: [160, 162, 165, 158, 164]\n","\n","## Region B: [172, 175, 170, 168, 174]\n","\n","## Region C: [180, 182, 179, 185, 183]\n","\n","## Task: Write Python code to perform the one-way ANOVA and interpret the results.\n","\n","## Objective: Learn how to perform one-way ANOVA using Python and interpret F-statistic and p-value.\n","\n","\n","ans)     Here's how to perform a one-way ANOVA using Python:\n","\n","\n","import numpy as np\n","from scipy.stats import f_oneway\n","\n","# Data for Region A, Region B, and Region C\n","region_a = np.array([160, 162, 165, 158, 164])\n","region_b = np.array([172, 175, 170, 168, 174])\n","region_c = np.array([180, 182, 179, 185, 183])\n","\n","# Perform one-way ANOVA\n","f_statistic, p_value = f_oneway(region_a, region_b, region_c)\n","\n","print(\"F-statistic:\", f_statistic)\n","print(\"p-value:\", p_value)\n","``\n","\n","**Interpretation:**\n","\n","*   If the p-value is below a certain significance level (e.g., 0.05), we reject the null hypothesis that the means are equal.\n","*   If the p-value is above the significance level, we fail to reject the null hypothesis.\n","\n","**Example Output:**\n","\n","\n","F-statistic: 53.166666666666664\n","p-value: 1.3877787807814456e-07\n","\n","\n","**Conclusion:**\n","\n","Based on the one-way ANOVA, we reject the null hypothesis (p-value ≈ 0 < 0.05). This suggests that there are statistically significant differences in average heights among the three regions.\n","\n","**Post-hoc analysis:**\n","\n","To determine which regions have significantly different means, perform a post-hoc test like Tukey's HSD or Scheffé test.\n","\n","python\n","import statsmodels.api as sm\n","from statsmodels.stats.multicomp import pairwise_tukeyhsd\n","\n","# Combined data\n","data = np.concatenate((region_a, region_b, region_c))\n","\n","# Group labels\n","groups = ['A'] * len(region_a) + ['B'] * len(region_b) + ['C'] * len(region_c)\n","\n","# Tukey's HSD test\n","tukey = pairwise_tukeyhsd(endog=data, groups=groups, alpha=0.05)\n","\n","print(tukey)\n","```\n","\n","This will provide pairwise comparisons and significance levels.\n"],"metadata":{"id":"K1jPvZb-JHnu"},"execution_count":null,"outputs":[]}]}